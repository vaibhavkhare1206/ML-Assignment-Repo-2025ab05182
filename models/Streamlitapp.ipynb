{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9754,"status":"ok","timestamp":1770831969861,"user":{"displayName":"VAIBHAV KHARE","userId":"12914748460286101071"},"user_tz":-330},"id":"LSfGTJNuNQp0","outputId":"54efc160-5a33-4fb6-8690-f32fbc7e2118"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting streamlit\n","  Downloading streamlit-1.54.0-py3-none-any.whl.metadata (9.8 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n","Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n","Collecting cachetools<7,>=5.5 (from streamlit)\n","  Downloading cachetools-6.2.6-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.46)\n","Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (26.0)\n","Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n","Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.6)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.3)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n","Requirement already satisfied: typing-extensions<5,>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.26.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2026.1.4)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n","Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n","Downloading streamlit-1.54.0-py3-none-any.whl (9.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cachetools-6.2.6-py3-none-any.whl (11 kB)\n","Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m128.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: cachetools, pydeck, streamlit\n","  Attempting uninstall: cachetools\n","    Found existing installation: cachetools 7.0.0\n","    Uninstalling cachetools-7.0.0:\n","      Successfully uninstalled cachetools-7.0.0\n","Successfully installed cachetools-6.2.6 pydeck-0.9.1 streamlit-1.54.0\n"]}],"source":["pip install streamlit pandas numpy joblib scikit-learn matplotlib seaborn"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1b165c1c","executionInfo":{"status":"ok","timestamp":1770831969862,"user_tz":-330,"elapsed":12,"user":{"displayName":"VAIBHAV KHARE","userId":"12914748460286101071"}},"outputId":"2c215522-4530-42b9-e6b6-31a155ce9d9b"},"source":["%%writefile app.py\n","import os;\n","import sklearn\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import streamlit as st\n","import pandas as pd\n","import numpy as np\n","import requests # Import the requests library\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.datasets import make_classification\n","import xgboost as xgb\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_auc_score, matthews_corrcoef\n","\n","# 1. Set the Streamlit page configuration\n","st.set_page_config(\n","    page_title='Direct Marketing Campaigns on Portuguese Banking Data',\n","    layout='wide'\n",")\n","\n","\n","# Set 'Light Gray' as the default selected color\n","color_options = {\n","    'Light Gray': '#D3D3D3',\n","    'Black': '#000000'\n","}\n","\n","# 2. Set the main title of the Streamlit application\n","st.title('Direct Marketing Campaigns on Portuguese Banking Data')\n","\n","# Add developer header\n","st.header('Developed by Vaibhav Khare - BITS ID: 2025ab05182@wilp.bits-pilani.ac.in')\n","\n","# Initialize session state variables if they don't exist\n","if 'df_processed' not in st.session_state:\n","    st.session_state['df_processed'] = None\n","if 'X_train' not in st.session_state:\n","    st.session_state['X_train'] = None\n","if 'X_test' not in st.session_state:\n","    st.session_state['X_test'] = None\n","if 'y_train' not in st.session_state:\n","    st.session_state['y_train'] = None\n","if 'y_test' not in st.session_state:\n","    st.session_state['y_test'] = None\n","if 'model' not in st.session_state:\n","    st.session_state['model'] = None\n","if 'y_pred' not in st.session_state:\n","    st.session_state['y_pred'] = None\n","if 'selected_model' not in st.session_state:\n","    st.session_state['selected_model'] = 'Logistic Regression' # Default selection\n","if 'original_df' not in st.session_state: # Initialize original_df\n","    st.session_state['original_df'] = None\n","\n","# --- Data Upload ---\n","st.header('Data Upload - Upload Your Test Data')\n","uploaded_file = st.file_uploader(\"Upload your CSV file\", type=[\"csv\"])\n","\n","# --- Download Sample Data ---\n","st.subheader(\"Or download a sample test file:\")\n","sample_data_url = 'https://raw.githubusercontent.com/vaibhavkhare1206/ML-Assignment-Repo-2025ab05182/main/data/bank-test.csv'\n","\n","try:\n","    response = requests.get(sample_data_url)\n","    if response.status_code == 200:\n","        st.download_button(\n","            label=\"Download Sample 'bank-test.csv'\",\n","            data=response.content,\n","            file_name=\"bank-test.csv\",\n","            mime=\"text/csv\"\n","        )\n","    else:\n","        st.error(f\"Failed to fetch sample data from URL. Status code: {response.status_code}\")\n","except requests.exceptions.RequestException as e:\n","    st.error(f\"Error fetching sample data: {e}\")\n","\n","\n","\n","if uploaded_file is not None:\n","    try:\n","        df = pd.read_csv(uploaded_file)\n","        st.success(\"File uploaded successfully! Here's a preview of your data:\")\n","        st.dataframe(df.head())\n","        st.session_state['original_df'] = df.copy() # Store original for potential re-preprocessing\n","    except Exception as e:\n","        st.error(f\"Error loading file: {e}\")\n","else:\n","    st.info(\"Please upload a CSV file to get started.\")\n","\n","# --- Data Preprocessing ---\n","st.header('Data Preprocessing')\n","if st.session_state['original_df'] is not None:\n","    df = st.session_state['original_df'].copy()\n","\n","    # Convert target variable 'y' from 'yes'/'no' to 1/0\n","    if 'y' in df.columns:\n","        df['y'] = df['y'].map({'yes': 1, 'no': 0})\n","        st.write(\"Target variable 'y' converted to numerical (1/0).\")\n","    else:\n","        st.warning(\"Target variable 'y' not found. Ensure the dataset contains a 'y' column.\")\n","\n","    # Identify categorical and numerical columns\n","    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n","    numerical_cols = df.select_dtypes(include=['number']).columns.tolist()\n","\n","    # Remove 'y' from categorical_cols if it's there (after conversion it's numerical)\n","    if 'y' in categorical_cols:\n","        categorical_cols.remove('y')\n","\n","    # Apply one-hot encoding to categorical columns\n","    if categorical_cols:\n","        df_processed = pd.get_dummies(df, columns=categorical_cols, drop_first=True, dtype=int)\n","        st.write(f\"One-hot encoding applied to categorical columns: {', '.join(categorical_cols)}.\")\n","    else:\n","        df_processed = df.copy()\n","        st.info(\"No categorical columns found for one-hot encoding.\")\n","\n","    # --- Add Missing Value Handling ---\n","    st.subheader(\"Handling Missing Values\")\n","\n","    # Identify columns with NaN values\n","    missing_cols_nan = df_processed.columns[df_processed.isnull().any()].tolist()\n","\n","    # Identify columns with infinite values (only check numerical columns)\n","    numerical_cols_in_processed_df = df_processed.select_dtypes(include=np.number).columns\n","    missing_cols_inf = [col for col in numerical_cols_in_processed_df if np.isinf(df_processed[col]).any()]\n","\n","    if missing_cols_nan or missing_cols_inf:\n","        st.warning(\"Found missing or infinite values. Handling them...\")\n","\n","        # Handle NaN values\n","        if missing_cols_nan:\n","            st.write(f\"Imputing NaN values in columns: {', '.join(missing_cols_nan)} with mean/mode.\")\n","            for col in missing_cols_nan:\n","                if df_processed[col].dtype in ['int64', 'float64']:\n","                    # Calculate mean, if mean is NaN (meaning all values are NaN), use 0 as fallback\n","                    imputation_value = df_processed[col].mean()\n","                    if pd.isna(imputation_value):\n","                        imputation_value = 0 # Fallback for entirely NaN numerical columns\n","                    df_processed[col].fillna(imputation_value, inplace=True)\n","                else:\n","                    # For non-numeric NaNs, use mode. Handle case where mode might be empty (e.g., all NaN)\n","                    if not df_processed[col].mode().empty:\n","                        df_processed[col].fillna(df_processed[col].mode()[0], inplace=True)\n","                    else:\n","                        df_processed[col].fillna('unknown', inplace=True) # Fallback for entirely NaN object columns\n","\n","        # Handle infinite values\n","        if missing_cols_inf:\n","            st.write(f\"Replacing infinite values in columns: {', '.join(missing_cols_inf)} with NaN, then re-imputing with mean.\")\n","            for col in missing_cols_inf:\n","                # Replace inf with NaN first\n","                df_processed[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n","                # Re-impute if it was originally inf, now NaN. Use 0 as fallback if mean is NaN.\n","                if df_processed[col].isnull().any():\n","                     imputation_value = df_processed[col].mean()\n","                     if pd.isna(imputation_value):\n","                         imputation_value = 0 # Fallback for entirely NaN numerical columns after inf replacement\n","                     df_processed[col].fillna(imputation_value, inplace=True)\n","\n","        st.success(\"Missing and infinite values handled.\")\n","    else:\n","        st.info(\"No missing or infinite values found.\")\n","\n","    st.subheader(\"Preprocessed Data Preview:\")\n","    st.dataframe(df_processed.head())\n","    st.session_state['df_processed'] = df_processed\n","\n","# --- Data Splitting ---\n","st.header('Data Splitting')\n","if st.session_state['df_processed'] is not None:\n","    df_processed = st.session_state['df_processed']\n","\n","    if 'y' in df_processed.columns:\n","        X = df_processed.drop('y', axis=1)\n","        y = df_processed['y']\n","        st.write(\"Features (X) and target (y) defined.\")\n","\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","        st.write(\"Data split into training and testing sets.\")\n","\n","        st.subheader(\"Shapes of Training and Testing Sets:\")\n","        st.write(f\"X_train shape: {X_train.shape}\")\n","        st.write(f\"y_train shape: {y_train.shape}\")\n","        st.write(f\"X_test shape: {X_test.shape}\")\n","        st.write(f\"y_test shape: {y_test.shape}\")\n","\n","        st.session_state['X_train'] = X_train\n","        st.session_state['X_test'] = X_test\n","        st.session_state['y_train'] = y_train\n","        st.session_state['y_test'] = y_test\n","\n","    else:\n","        st.error(\"Target variable 'y' not found in the processed DataFrame. Cannot split data.\")\n","\n","# --- Model Selection ---\n","st.sidebar.header('Model Selection')\n","model_options = [\n","    'Logistic Regression',\n","    'Decision Tree Classifier',\n","    'K-Nearest Neighbor Classifier',\n","    'Naive Bayes Classifier (Gaussian Model)',\n","    'Random Forest Model',\n","    'XGBoost Model'\n","]\n","\n","st.session_state['selected_model'] = st.sidebar.selectbox(\n","    'Choose a Classification Model',\n","    model_options,\n","    index=model_options.index(st.session_state['selected_model'])\n",")\n","st.sidebar.write(f\"You selected the **{st.session_state['selected_model']}** model.\")\n","\n","# --- Model Training ---\n","st.header('Model Training')\n","if st.session_state['X_train'] is not None and st.session_state['y_train'] is not None:\n","    X_train = st.session_state['X_train']\n","    y_train = st.session_state['y_train']\n","    X_test = st.session_state['X_test']\n","\n","    if st.button('Train Model'):\n","        st.info(f\"Training {st.session_state['selected_model']}...\")\n","        try:\n","            model = None\n","            if st.session_state['selected_model'] == 'Logistic Regression':\n","                model = LogisticRegression(random_state=42, solver='liblinear')\n","            elif st.session_state['selected_model'] == 'Decision Tree Classifier':\n","                model = DecisionTreeClassifier(random_state=42)\n","            elif st.session_state['selected_model'] == 'K-Nearest Neighbor Classifier':\n","                model = KNeighborsClassifier()\n","            elif st.session_state['selected_model'] == 'Naive Bayes Classifier (Gaussian Model)':\n","                model = GaussianNB()\n","            elif st.session_state['selected_model'] == 'Random Forest Model':\n","                model = RandomForestClassifier(n_estimators=10, random_state=42)\n","                model.fit(X_train, y_train)\n","            elif st.session_state['selected_model'] == 'XGBoost Model':\n","                model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', objective='binary:logistic')\n","\n","            if model:\n","                model.fit(X_train, y_train)\n","                st.success(f\"{st.session_state['selected_model']} trained successfully!\")\n","                st.session_state['model'] = model\n","                st.session_state['y_pred'] = model.predict(X_test)\n","\n","                # Modified block to handle AttributeError robustly\n","                if st.session_state['selected_model'] == 'Random Forest Model':\n","                    try:\n","                        num_estimators = len(model.estimators_)\n","                        st.info(f\"Number of estimators (trees) in the Random Forest model: {num_estimators}\")\n","                    except AttributeError:\n","                        st.warning(\"Could not access 'estimators_' attribute for Random Forest model after training. Ensure the model fitted successfully.\")\n","            else:\n","                st.error(\"No model selected or initialized.\")\n","        except Exception as e:\n","            st.error(f\"Error training model: {e}\")\n","\n","    if st.session_state['model'] is not None:\n","        st.success(\"Model ready for evaluation.\")\n","    else:\n","        st.info(\"Click 'Train Model' to begin.\")\n","else:\n","    st.warning(\"Please upload data and complete preprocessing/splitting steps to train a model.\")\n","\n","# --- Model Evaluation ---\n","st.header('Model Evaluation')\n","if st.session_state['model'] is not None and st.session_state['y_test'] is not None and st.session_state['y_pred'] is not None:\n","    y_test = st.session_state['y_test']\n","    y_pred = st.session_state['y_pred']\n","\n","    if y_test.empty or len(y_pred) == 0:\n","        st.warning(\"y_test or y_pred is empty. Cannot evaluate an empty set.\")\n","    else:\n","        st.write(f\"Evaluating {st.session_state['selected_model']}:\")\n","\n","        # Calculate metrics\n","        accuracy = accuracy_score(y_test, y_pred)\n","        precision = precision_score(y_test, y_pred, zero_division=0)\n","        recall = recall_score(y_test, y_pred, zero_division=0)\n","        f1 = f1_score(y_test, y_pred, zero_division=0)\n","        # Ensure predict_proba is available and model is fitted for AUC score\n","        if hasattr(st.session_state['model'], 'predict_proba'):\n","            try:\n","                auc_score = roc_auc_score(y_test, st.session_state['model'].predict_proba(st.session_state['X_test'])[:, 1])\n","            except Exception as e:\n","                st.warning(f\"Could not calculate AUC score: {e}. Some models may not support predict_proba or require specific data types.\")\n","                auc_score = 'N/A'\n","        else:\n","            st.warning(\"Selected model does not have a 'predict_proba' method for AUC calculation.\")\n","            auc_score = 'N/A'\n","\n","        mcc = matthews_corrcoef(y_test, y_pred)\n","\n","        # Display metrics in a table\n","        metrics_data = {\n","            'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC Score', 'Matthews Correlation Coefficient (MCC)'] ,\n","            'Value': [accuracy, precision, recall, f1, auc_score, mcc]\n","        }\n","        metrics_df = pd.DataFrame(metrics_data)\n","        st.subheader(\"Evaluation Matrix\")\n","        st.dataframe(metrics_df.set_index('Metric'))\n","\n","        # Display Classification Report\n","        st.subheader(\"Classification Report\")\n","        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n","        report_df = pd.DataFrame(report).transpose()\n","        st.dataframe(report_df)\n","\n","        # Display Confusion Matrix\n","        st.subheader(\"Confusion Matrix\")\n","        cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n","        cm_df = pd.DataFrame(cm, index=['Actual Negative (0)', 'Actual Positive (1)'], columns=['Predicted Negative (0)', 'Predicted Positive (1)'])\n","        st.dataframe(cm_df)\n","else:\n","    st.warning(\"Please train a model to see evaluation metrics.\")\n","\n","# --- Reset Button ---\n","st.sidebar.markdown(\"---\")\n","if st.sidebar.button('Clear Results and Reset'):\n","    for key in st.session_state.keys():\n","        del st.session_state[key]\n","    st.rerun()"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing app.py\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3a885500","outputId":"ae87a18e-d702-401c-b5e1-2b3dcc589337"},"source":["!streamlit run app.py"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n","\u001b[0m\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.168.64.140:8501\u001b[0m\n","\u001b[0m\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}